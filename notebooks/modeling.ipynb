{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ac40eb5-52d6-4003-a850-1afa111eeda7",
   "metadata": {},
   "source": [
    "# Análise de Crédito - Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed582f0f-12dc-4095-bef1-7fe4ec234a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d1dcc1f-088c-47a0-999e-6cec5a92dc76",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4fef5841-15df-4e9c-b415-ea461dca5dff",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'optuna'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshap\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01moptuna\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m time\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'optuna'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import typing\n",
    "import shap\n",
    "import warnings\n",
    "import optuna\n",
    "from utils import *\n",
    "from time import time\n",
    "from pathlib import Path\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af1775a0-9ae1-473c-bf1f-222d0a154f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a02444-748c-4766-b5a7-5a5d1e315944",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b2e7f97-2350-44f8-b97f-3e1e8ec75740",
   "metadata": {},
   "outputs": [],
   "source": [
    "REMOVE_MISSING  = [\"loan_term\"]\n",
    "REMOVE_BIAS = [\"age\", \"city\", \"state\", \"gender\", \"education_level\", \"zip_code\",\"marital_status\"]\n",
    "REMOVE_ID_COLUMN = [\"id\"]\n",
    "REMOVE_UNUSED_COLUMNS = [\"informed_purpose\", \"pre_approved\"]\n",
    "DATASET = Path(\"../datasets/dataset_cleaned.csv\")\n",
    "TARGET_VARIABLE = \"sent_to_analysis\"\n",
    "TARGET_ENCODER = []\n",
    "FEATURES = [\"monthly_income\", 'collateral_value', \"loan_amount\", \"collateral_debt\",\"verified_restriction\", \"dishonored_checks\", \n",
    "            \"expired_debts\", \"banking_debts\", \"commercial_debts\", \"protests\", \"informed_restriction\", \"monthly_payment\", \"auto_brand\",\n",
    "            \"auto_model\", \"auto_year\", \"form_completed\", \"channel\", \"landing_page\", \"landing_page_product\", \"utm_term\"]\n",
    "TARGET_VARIABLE = \"sent_to_analysis\"\n",
    "CAT_FEATURES = [\"auto_brand\",\"auto_model\",\"channel\",\"landing_page\",\"landing_page_product\",\"utm_term\"]\n",
    "TARGET_ENCODER = [\"auto_brand\",\"auto_model\",\"channel\",\"landing_page\",\"landing_page_product\",\"utm_term\"]\n",
    "KFOLD = 5\n",
    "TOTAL_MODELS_TESTED = 2 # Verificar um jeito melhor de dar assign nessa variável\n",
    "N_TRIALS = 2\n",
    "TIMEOUT = 100*3\n",
    "K_FOLDS = KFold(n_splits = KFOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a454d10a-9ece-464f-b0e4-bd155ab15e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LGB_PARAMS = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'max_depth': -1,\n",
    "    'verbosity': -1,\n",
    "    'n_estimators': 100,\n",
    "    'max_bin': 1024,\n",
    "    'boosting_type': 'gbdt', #'dart'\n",
    "    'colsample_bytree': 0.5673775386473462,        \n",
    "    'eta': 0.05446876730023387,\n",
    "    'reg_lambda': 10.787843597294561,\n",
    "    'min_child_samples': 69,\n",
    "    'random_state': SEED,\n",
    "    'early_stopping_rounds': 150,\n",
    "    'verbose':1,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cd72c0-ac25-4fed-aa0c-aa464ff43785",
   "metadata": {},
   "source": [
    "# Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6aefedf-b266-42c8-a995-86ae8cb19034",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.seed = SEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb411801-0996-4810-97c9-0e3322b1b230",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TargetEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, cols=None):\n",
    "        self.cols = cols\n",
    "        self.target_means_ = {}\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X = pd.DataFrame(X)\n",
    "        y = pd.Series(y)\n",
    "        self.target_means_ = {}\n",
    "        for col in self.cols:\n",
    "            self.target_means_[col] = y.groupby(X[col]).mean()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = pd.DataFrame(X)\n",
    "        X_transformed = X.copy()\n",
    "        for col in self.cols:\n",
    "            X_transformed[col] = X[col].map(self.target_means_[col])\n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f2cf185-cb14-47eb-829f-9127fc735090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(df_train:pd.DataFrame ,df_test: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    encoder = TargetEncoder(cols=TARGET_ENCODER)\n",
    "    encoder.fit(df_train, df_train[TARGET_VARIABLE])\n",
    "    df_train[TARGET_ENCODER] = encoder.transform(df_train[TARGET_ENCODER])\n",
    "    df_test[TARGET_ENCODER] = encoder.transform(df_test[TARGET_ENCODER])\n",
    "\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea038c6b-9f8d-4e71-be44-8b74c26ec681",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_validate_model(train: pd.DataFrame, test: pd.DataFrame, model, features_col:  typing.List[str], categorical_feature: typing.List[str] = None) -> dict[str, typing.Any]:\n",
    "    if isinstance(model, LGBMClassifier):\n",
    "        model = model.fit(train[features_col],train[TARGET_VARIABLE], categorical_feature=categorical_feature)\n",
    "    else:\n",
    "        model = model.fit(train[features_col],train[TARGET_VARIABLE])\n",
    "        \n",
    "    output = model.predict(test[features_col])\n",
    "\n",
    "    artifact = {}\n",
    "\n",
    "    metrics = calculate_metrics(output, test[TARGET_VARIABLE])\n",
    "    \n",
    "    artifact[\"metrics\"] = metrics\n",
    "    return artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "293c30dc-806e-469b-bd40-ec83736f3d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(output, real) -> dict[str, float]:\n",
    "    precision, recall, thresholds = precision_recall_curve(real, output)\n",
    "    # Use AUC function to calculate the area under the curve of precision recall curve\n",
    "    auc_precision_recall = auc(recall, precision)\n",
    "    roc_auc = roc_auc_score(real, output)\n",
    "\n",
    "    metrics = {}\n",
    "    metrics[\"pr_auc\"] = auc_precision_recall\n",
    "    metrics[\"auc\"] = roc_auc\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6acd0c3e-cb6d-43ae-8daf-7376d932e174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optuna_search(data):\n",
    "    \n",
    "    start = time()\n",
    "    # Optuna study for Lightgbm\n",
    "    study = optuna.create_study(study_name='Study', direction='maximize')\n",
    "    with tqdm(total=N_TRIALS, desc=\"Optimizing\", unit=\"trial\") as pbar:\n",
    "        study.optimize(lambda trial: objective(trial, data), n_trials=N_TRIALS, callbacks=[tqdm_callback], timeout=TIMEOUT)\n",
    "\n",
    "    print(f'Time spent[s]: {(time()-start)/60:.2f} minutes')\n",
    "    \n",
    "    print('N trials: ', len(study.trials))\n",
    "    print('Best trial:')\n",
    "    trial = study.best_trial \n",
    "\n",
    "    print('  Valor: {}'.format(trial.value))\n",
    "    print('  Params: ')\n",
    "    for key, value in trial.params.items():\n",
    "        print('    {}: {}'.format(key, value))\n",
    "        \n",
    "    optuna_params = trial.params\n",
    "    LGB_PARAMS.update(optuna_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f0972dda-bbba-40e8-af78-5ca63f33f45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_lgbm(trial, data):\n",
    "    max_depth = -1\n",
    "    params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'verbosity': 0,\n",
    "        'max_bin': 1024,\n",
    "        'boosting_type': 'gbdt', #'gbdt'\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 0.8),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2 ** (max_depth - 1), 2 ** max_depth),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 0.8),        \n",
    "        'eta': trial.suggest_float('eta', 0.05, 0.1),\n",
    "        'lambda_l1': trial.suggest_float(\"reg_alpha\", 1e-6, 1e-3),\n",
    "        'lambda_l2': trial.suggest_float(\"reg_lambda\", 10, 150),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'min_split_gain': trial.suggest_float('min_split_gain', 0.0, 0.1),\n",
    "        'min_child_weight': trial.suggest_float('min_child_weight', 1e-3, 10),\n",
    "        'random_state': SEED,\n",
    "        'early_stopping_rounds': 150,\n",
    "        #'scale_pos_weight': scale_pos_weight,\n",
    "        #'device_type': 'GPU',\n",
    "    }\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(K_FOLDS.split(data)):\n",
    "\n",
    "        print(f\"Fold {i+1}:\")    \n",
    "    \n",
    "        df_train, df_test = data.iloc[train_index], data.iloc[test_index]\n",
    "        df_train, df_test = encoder(df_train, df_test)\n",
    "    \n",
    "        lgbm = LGBMClassifier(params)\n",
    "    \n",
    "        df_train, df_test = encoder(df_train, df_test)\n",
    "        artifact_xgb = fit_and_validate_model(df_train, df_test, xgb, FEATURES)\n",
    "        artifact_lgbm = fit_and_validate_model(df_train, df_test, lgbm, FEATURES, CAT_FEATURES)\n",
    "        \n",
    "        xgb_metrics_pr_auc.append(artifact_xgb[\"metrics\"][\"pr_auc\"])\n",
    "        xgb_metrics_roc_auc.append(artifact_xgb[\"metrics\"][\"auc\"])\n",
    "\n",
    "        del df_train, df_test, lgbm\n",
    "        gc.collect()\n",
    "        \n",
    "\n",
    "    return np.mean(xgb_metrics_pr_auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba0ca9d-4ee2-42a9-ae83-4fbf39754ae4",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7859cab8-6641-438c-8899-4422218cd35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_dataset(DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "103f386e-6f83-4d07-bbfb-a14eccebe291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>monthly_income</th>\n",
       "      <th>collateral_value</th>\n",
       "      <th>loan_amount</th>\n",
       "      <th>collateral_debt</th>\n",
       "      <th>verified_restriction</th>\n",
       "      <th>dishonored_checks</th>\n",
       "      <th>expired_debts</th>\n",
       "      <th>banking_debts</th>\n",
       "      <th>commercial_debts</th>\n",
       "      <th>protests</th>\n",
       "      <th>...</th>\n",
       "      <th>monthly_payment</th>\n",
       "      <th>auto_brand</th>\n",
       "      <th>auto_model</th>\n",
       "      <th>auto_year</th>\n",
       "      <th>form_completed</th>\n",
       "      <th>sent_to_analysis</th>\n",
       "      <th>channel</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>landing_page_product</th>\n",
       "      <th>utm_term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5668.0</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>161.77</td>\n",
       "      <td>Nissan</td>\n",
       "      <td>LIVINA 1.6 16V Flex Fuel 5p</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>search</td>\n",
       "      <td>/emprestimos/solicitar</td>\n",
       "      <td>PersonalLoan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5000.0</td>\n",
       "      <td>14200.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>279.56</td>\n",
       "      <td>VW - VolksWagen</td>\n",
       "      <td>Fox City 1.0Mi/ 1.0Mi Total Flex 8V 3p</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>direct</td>\n",
       "      <td>/emprestimos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000.0</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>1060.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>447.30</td>\n",
       "      <td>Fiat</td>\n",
       "      <td>Palio 1.0 ECONOMY Fire Flex 8V 4p</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>affiliates</td>\n",
       "      <td>/emprestimos/garantia-veiculo/solicitar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7500.0</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>670.95</td>\n",
       "      <td>GM - Chevrolet</td>\n",
       "      <td>Classic/ Classic LS 1.0 VHC FlexPower 4p</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>social</td>\n",
       "      <td>/emprestimos/solicitar</td>\n",
       "      <td>PersonalLoan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3379.0</td>\n",
       "      <td>16500.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>333.33</td>\n",
       "      <td>GM - Chevrolet</td>\n",
       "      <td>Celta Life/ LS 1.0 MPFI 8V FlexPower 5p</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>search</td>\n",
       "      <td>/emprestimos/solicitar</td>\n",
       "      <td>PersonalLoan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   monthly_income  collateral_value  loan_amount  collateral_debt  \\\n",
       "0          5668.0           24000.0       5000.0            900.0   \n",
       "1          5000.0           14200.0       5000.0           1500.0   \n",
       "2          3000.0           17000.0       8000.0           1060.0   \n",
       "3          7500.0           21000.0      12000.0              0.0   \n",
       "4          3379.0           16500.0       5000.0              0.0   \n",
       "\n",
       "   verified_restriction  dishonored_checks  expired_debts  banking_debts  \\\n",
       "0                   0.0                  0              0              0   \n",
       "1                   0.0                  0              0              0   \n",
       "2                   0.0                  0              0              0   \n",
       "3                   1.0                  0              0              0   \n",
       "4                   0.0                  0              0              0   \n",
       "\n",
       "   commercial_debts  protests  ...  monthly_payment       auto_brand  \\\n",
       "0                 0         0  ...           161.77           Nissan   \n",
       "1                 0         0  ...           279.56  VW - VolksWagen   \n",
       "2                 0         0  ...           447.30             Fiat   \n",
       "3                 0         0  ...           670.95   GM - Chevrolet   \n",
       "4                 0         0  ...           333.33   GM - Chevrolet   \n",
       "\n",
       "                                 auto_model auto_year  form_completed  \\\n",
       "0               LIVINA 1.6 16V Flex Fuel 5p    2011.0             0.0   \n",
       "1    Fox City 1.0Mi/ 1.0Mi Total Flex 8V 3p    2004.0             0.0   \n",
       "2         Palio 1.0 ECONOMY Fire Flex 8V 4p    2010.0             0.0   \n",
       "3  Classic/ Classic LS 1.0 VHC FlexPower 4p    2012.0             0.0   \n",
       "4   Celta Life/ LS 1.0 MPFI 8V FlexPower 5p    2008.0             0.0   \n",
       "\n",
       "   sent_to_analysis     channel                             landing_page  \\\n",
       "0               0.0      search                   /emprestimos/solicitar   \n",
       "1               0.0      direct                             /emprestimos   \n",
       "2               0.0  affiliates  /emprestimos/garantia-veiculo/solicitar   \n",
       "3               0.0      social                   /emprestimos/solicitar   \n",
       "4               0.0      search                   /emprestimos/solicitar   \n",
       "\n",
       "  landing_page_product utm_term  \n",
       "0         PersonalLoan      NaN  \n",
       "1                  NaN      NaN  \n",
       "2                  NaN      NaN  \n",
       "3         PersonalLoan      NaN  \n",
       "4         PersonalLoan      NaN  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove columns that will not be used for modelling\n",
    "df_cleaned = df.drop(REMOVE_BIAS + REMOVE_ID_COLUMN + REMOVE_MISSING + REMOVE_UNUSED_COLUMNS, axis=1)\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c937dd-e9c1-4a6c-9231-378be8e51e7a",
   "metadata": {},
   "source": [
    "# XGBoost & LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46b940bd-e163-4d9d-a9a6-026d508d5a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e992e154-07f8-43de-bc8d-c89cb34d58e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 2612, number of negative: 9345\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000335 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1300\n",
      "[LightGBM] [Info] Number of data points in the train set: 11957, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.218449 -> initscore=-1.274725\n",
      "[LightGBM] [Info] Start training from score -1.274725\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Fold 2:\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 2475, number of negative: 9482\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000351 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1289\n",
      "[LightGBM] [Info] Number of data points in the train set: 11957, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.206992 -> initscore=-1.343155\n",
      "[LightGBM] [Info] Start training from score -1.343155\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Fold 3:\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 2421, number of negative: 9537\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000301 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1301\n",
      "[LightGBM] [Info] Number of data points in the train set: 11958, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202459 -> initscore=-1.370998\n",
      "[LightGBM] [Info] Start training from score -1.370998\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Fold 4:\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 2640, number of negative: 9318\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000277 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1301\n",
      "[LightGBM] [Info] Number of data points in the train set: 11958, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.220773 -> initscore=-1.261169\n",
      "[LightGBM] [Info] Start training from score -1.261169\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Fold 5:\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 2912, number of negative: 9046\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000262 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1290\n",
      "[LightGBM] [Info] Number of data points in the train set: 11958, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.243519 -> initscore=-1.133483\n",
      "[LightGBM] [Info] Start training from score -1.133483\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n"
     ]
    }
   ],
   "source": [
    "xgb_metrics_pr_auc = list()\n",
    "lgbm_metrics_pr_auc = list()\n",
    "xgb_metrics_roc_auc = list()\n",
    "lgbm_metrics_roc_auc = list()\n",
    "\n",
    "metrics_pdf_pr = pd.DataFrame()\n",
    "metrics_pdf_auc = pd.DataFrame()\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(K_FOLDS.split(data)):\n",
    "\n",
    "    print(f\"Fold {i+1}:\")    \n",
    "\n",
    "    df_train, df_test = data.iloc[train_index], data.iloc[test_index]\n",
    "    df_train, df_test = encoder(df_train, df_test)\n",
    "\n",
    "    xgb = XGBClassifier(n_estimators=100, max_depth=10)\n",
    "    lgbm = LGBMClassifier(n_estimators=100, max_depth=10)\n",
    "\n",
    "    df_train.to_pickle(f\"df_train_fold_{i+1}.pkl\")\n",
    "    df_test.to_pickle(f\"df_test_fold_{i+1}.pkl\")\n",
    "\n",
    "    df_train, df_test = encoder(df_train, df_test)\n",
    "    artifact_xgb = fit_and_validate_model(df_train, df_test, xgb, FEATURES)\n",
    "    artifact_lgbm = fit_and_validate_model(df_train, df_test, lgbm, FEATURES, CAT_FEATURES)\n",
    "    \n",
    "    xgb.save_model(f\"xgb_model_fold_{i+1}.json\")\n",
    "    lgbm.booster_.save_model(f\"lgbm_model_fold_{i+1}.txt\")\n",
    "\n",
    "    \n",
    "    xgb_metrics_pr_auc.append(artifact_xgb[\"metrics\"][\"pr_auc\"])\n",
    "    lgbm_metrics_pr_auc.append(artifact_lgbm[\"metrics\"][\"pr_auc\"])\n",
    "    xgb_metrics_roc_auc.append(artifact_xgb[\"metrics\"][\"auc\"])\n",
    "    lgbm_metrics_roc_auc.append(artifact_lgbm[\"metrics\"][\"auc\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e72bf835-1496-4ad4-a71f-75065e058a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_pdf_pr[\"value\"] = xgb_metrics_pr_auc + lgbm_metrics_pr_auc\n",
    "metrics_pdf_pr[\"metric\"] = [\"pr_auc\"] * KFOLD * TOTAL_MODELS_TESTED # Total de modelos = 2\n",
    "metrics_pdf_pr[\"fold\"] =  TOTAL_MODELS_TESTED * list(range(1,KFOLD+1))\n",
    "metrics_pdf_pr[\"model\"] = [\"xgb\"] * KFOLD + [\"lgbm\"] * KFOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da11a82b-bd41-4f47-ba58-ace1c72c4639",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_pdf_auc[\"value\"] = xgb_metrics_roc_auc + lgbm_metrics_roc_auc\n",
    "metrics_pdf_auc[\"metric\"] = [\"roc_auc\"] * KFOLD * TOTAL_MODELS_TESTED # Total de modelos = 2\n",
    "metrics_pdf_auc[\"fold\"] =  TOTAL_MODELS_TESTED * list(range(1,KFOLD+1))\n",
    "metrics_pdf_auc[\"model\"] = [\"xgb\"] * KFOLD + [\"lgbm\"] * KFOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "143d70da-3167-45e8-a152-dff854429791",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = pd.concat([metrics_pdf_pr, metrics_pdf_auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff76d265-26b1-4600-90ed-8de489f21c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics.to_csv(\"metrics.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fcd9a2-8187-4443-ac4a-cadb128c3640",
   "metadata": {},
   "source": [
    "# Optuna "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7a6323c1-dfe2-44d9-8637-a7555e0dee31",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optuna' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43moptuna_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[29], line 5\u001b[0m, in \u001b[0;36moptuna_search\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      3\u001b[0m start \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Optuna study for Lightgbm\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m study \u001b[38;5;241m=\u001b[39m \u001b[43moptuna\u001b[49m\u001b[38;5;241m.\u001b[39mcreate_study(study_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStudy\u001b[39m\u001b[38;5;124m'\u001b[39m, direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(total\u001b[38;5;241m=\u001b[39mN_TRIALS, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizing\u001b[39m\u001b[38;5;124m\"\u001b[39m, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrial\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m      7\u001b[0m     study\u001b[38;5;241m.\u001b[39moptimize(\u001b[38;5;28;01mlambda\u001b[39;00m trial: objective(trial, data), n_trials\u001b[38;5;241m=\u001b[39mN_TRIALS, callbacks\u001b[38;5;241m=\u001b[39m[tqdm_callback], timeout\u001b[38;5;241m=\u001b[39mTIMEOUT)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'optuna' is not defined"
     ]
    }
   ],
   "source": [
    "optuna_search(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02db5981-dcdd-4f36-96b4-2656a174fe8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
